{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"about_me/","title":"About Me","text":""},{"location":"podcast/","title":"Podcast","text":""},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tag:ai","title":"ai","text":"<ul> <li>            AI Gamer Project - Part 1 - Introduction          </li> <li>            AI Gamer Project - Part 2 - Setting Up          </li> <li>            AI Gamer Project - Part 3 - The AI Model          </li> </ul>"},{"location":"blog/","title":"Posts","text":""},{"location":"blog/2025/03/31/test-page/","title":"This is a test page","text":"<p>This is some content to test front matter parsing. </p> <p></p> <p>While I'm here I'm going to add another sentence!</p>"},{"location":"blog/2025/04/02/my-first-mkdocs-plugin/","title":"My first mkdocs plugin!","text":"<p>Now my blogs can be read to you!</p> <p></p> <p>I'm pretty excited for this preliminary push of an mkdocs plugin that leverages the amazon tts \"polly\" to create audio files for each blog on my site when it's built!</p> <p>This is a cool accessibiliy feature I've seen on some sites and I thought it would be really interesting to see if I could implement it on my site as well.</p> <p>ChatGPT got me started here but after some debugging and disecting I got it working. There are still some bugs but if you'd like to use it and contribute to it feel free!</p> <p>mkdocs-tts-amazon-polly</p> <p>Let me know what you think in the comments below! Also using this blog to test :P</p>"},{"location":"blog/2025/03/31/cicd-for-this-site/","title":"CI/CD for this site","text":"<p>This has been quite a day.</p> <p></p> <p>Along with working on-call I decided I would take on the CI/CD pipeline for automatic site builds.</p> <p>It's using github actions and while I'm still new to a lot of this I know enough to be dangerous.</p> <p>It's almost 1am so I'll make this brief. I wanted to use github actions to determine if my commit message started with buid. If it did then it would build the env and run the mike commands to deploy my site! Pretty cool! you'll be able to see previous versions of my site from a dropdown in the header. I may in the future tie these versions to something important but for now it's just a way for me to do a bit of archiving.</p>"},{"location":"blog/2025/04/03/ai-gamer-project---part-1---introduction/","title":"AI Gamer Project - Part 1 - Introduction","text":"<p>So I decided that I'm going to take a dive into AI...</p> <p></p> <p>I dabbled in it with the audio generation project for these blogs but I feel like that was a minimal use. So I'm using AI to help me learn AI. I'll be tackling this project in phases and will be documenting live!</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-1---introduction/#phase-1-infrastructure-setup","title":"Phase 1: Infrastructure Setup","text":"<p>Kubernetes on WSL \u2013 Set up a local Kubernetes cluster on your Windows machine using WSL. Minikube or K3s would be good lightweight options.</p> <p>Deploy Grafana &amp; Prometheus \u2013 Set up a monitoring stack within the cluster to collect and visualize metrics.</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-1---introduction/#phase-2-game-ai-integration","title":"Phase 2: Game &amp; AI Integration","text":"<p>Choose a Game \u2013 Select a game with a suitable interface for AI control. Something with a simple API or OpenAI Gym support would be ideal.</p> <p>Agentic AI Model \u2013 Start with a reinforcement learning (RL) model (e.g., PPO or DQN) using frameworks like Stable-Baselines3 or RLlib.</p> <p>Capture Gameplay &amp; Model Actions \u2013 Use OBS Studio (or a custom GStreamer setup) to stream the game and AI model decisions.</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-1---introduction/#phase-3-website-dashboard","title":"Phase 3: Website &amp; Dashboard","text":"<p>Live Streaming \u2013 Set up a video feed on your website (e.g., via RTMP to a web player).</p> <p>Metrics Dashboard \u2013 Expose model training insights and actions on Grafana, embedded below the stream.</p> <p>Would you like to start with setting up the Kubernetes cluster or the AI model?</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-1---introduction/#conclusion","title":"Conclusion","text":"<p>Wish me luck!!! This is going to be one hell of an adventure!</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/","title":"AI Gamer Project - Part 2 - Setting Up","text":"<p>This is going to be night one of the project.</p> <p>I'm hoping I can get the setup done in one go!. I'll leave my commands here in this blog incase you want to try to follow along. Bear in mind I'm going to be learning this as I go as well!</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/#step-1-prerequisites","title":"Step 1: Prerequisites","text":"<p>Ensure you have the following installed:</p> <ul> <li>WSL 2 with a Linux distribution (Ubuntu is recommended)</li> <li>Docker Desktop</li> <li>kubectl (Kubernetes CLI)</li> <li>Helm (for package management in Kubernetes)</li> <li>Minikube (or K3s, but we'll start with Minikube)</li> </ul> <p>I had WSL running on my system already so if you're jumping in you'll need to see how to do that yourself.</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/#docker","title":"Docker","text":"Update your package list and install dependencies<pre><code>sudo apt update &amp;&amp; sudo apt install ca-certificates curl gnupg\n</code></pre> Add Docker\u2019s official GPG key<pre><code>sudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo tee /etc/apt/keyrings/docker.asc &gt; /dev/null\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n</code></pre> <p>Add the Docker repository<pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> Install Docker<pre><code>sudo apt update &amp;&amp; sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre> Enable Docker to run without sudo (optional but recommended)<pre><code>sudo usermod -aG docker $USER\nnewgrp docker\n</code></pre> Verify Docker is installed correctly<pre><code>docker --version\ndocker run hello-world\n</code></pre></p> <p>Restart WSL<pre><code>wsl --shutdown\n</code></pre> then reopen WSL</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/#minikube","title":"minikube","text":"<p>install Minikube<pre><code>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n</code></pre> Start Minikube using Docker as the driver<pre><code>minikube start --driver=docker\n</code></pre> Verify that the cluster is running<pre><code>kubectl get nodes -A\n</code></pre></p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/#download-and-install-helm","title":"Download and Install Helm","text":"<p><pre><code># Add the Helm repository\ncurl -fsSL https://baltocdn.com/helm/signing.asc | sudo tee /usr/share/keyrings/helm.asc &gt; /dev/null\n</code></pre> <pre><code># Add the Helm APT Repo\necho \"deb [signed-by=/usr/share/keyrings/helm.asc] https://baltocdn.com/helm/stable/debian/ all main\" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list\n</code></pre> <pre><code># Update package lists and install Helm and Verify Install\nsudo apt update &amp;&amp; sudo apt install helm\nhelm version\n</code></pre></p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/#deploy-prometheus-and-grafana","title":"Deploy Prometheus and Grafana","text":"Add the helm repo and update<pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n</code></pre> Install prometheus and Grafana in Kubernetes<pre><code>helm install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace\nhelm install grafana grafana/grafana --namespace monitoring --set persistence.enabled=true --set persistence.size=10Gi\n</code></pre> <p>After install Grafana you'll get a prompt with how to get your admin password and how to access the application. Please note this command down so you can get this password when you need it.</p> Get Grafana admin password<pre><code>kubectl get secret --namespace monitoring grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n</code></pre> Verify a PVC was created for grafana so your dashboards persist<pre><code>kubectl get pvc -n monitoring\n</code></pre> Expose Grafana so you can acces it from your browser<pre><code>kubectl port-forward svc/grafana 3000:80 -n monitoring\n</code></pre> <p>http://localhost:3000</p> <p>Grafana is up and running</p> <p></p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-2---setting-up/#check-in","title":"Check in","text":"<p>How's your set up looking so far? </p> <p>So at this point my kubernetes cluster looks like this and hopefully yours does too! If you had any hang ups up to this point leave them in the comments below and I'll try to help!</p> <pre><code>kubectl get pods -A\nNAMESPACE     NAME                                                     READY   STATUS    RESTARTS      AGE\nkube-system   coredns-668d6bf9bc-5bd24                                 1/1     Running   0             25m\nkube-system   etcd-minikube                                            1/1     Running   0             25m\nkube-system   kube-apiserver-minikube                                  1/1     Running   0             25m\nkube-system   kube-controller-manager-minikube                         1/1     Running   0             25m\nkube-system   kube-proxy-zz6rd                                         1/1     Running   0             25m\nkube-system   kube-scheduler-minikube                                  1/1     Running   0             25m\nkube-system   storage-provisioner                                      1/1     Running   1 (24m ago)   25m\nmonitoring    alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running   0             2m13s\nmonitoring    grafana-677fb75ddd-48z2z                                 1/1     Running   0             77s\nmonitoring    prometheus-grafana-6854b47bf4-spd8b                      3/3     Running   0             2m26s\nmonitoring    prometheus-kube-prometheus-operator-7f8d744cd7-zsgh4     1/1     Running   0             2m26s\nmonitoring    prometheus-kube-state-metrics-f699c577d-45lff            1/1     Running   0             2m26s\nmonitoring    prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running   0             2m13s\nmonitoring    prometheus-prometheus-node-exporter-fk8rc                1/1     Running   0             2m26s\n</code></pre>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/","title":"AI Gamer Project - Part 3 - The AI Model","text":"<p>So far so good... is this where things get complicated?</p> <p>So now that my kubernetes cluster is stood up and looking good my AI assistant asked what I'd like to do next. I chose to set up the AI model.</p> <p>It gave the recommendation to use <code>Stable-Baselines3</code> as it supports algorithms like PPO and DQN. We'll go with that for now since we're learning </p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/#installing-more-dependencies","title":"Installing More Dependencies","text":"Install Dependencies<pre><code>sudo apt update &amp;&amp; sudo apt install python3-pip python3-venv\n</code></pre> Create a python virtual environment and install the library<pre><code>python3 -m venv ai-model-env\nsource ai-model-env/bin/activate\npip install stable-baselines3[extra] gymnasium numpy torch\n</code></pre> <p>pip install error</p> <p>I hit an issue with the above pip install cause I'm on zsh... If you hit an issue there you may need to run this instead</p> <pre><code>pip install 'stable-baselines3[extra]'\n</code></pre> Create and move into a working dir<pre><code>mkdir ~/ai-model &amp;&amp; cd ~/ai-model\n</code></pre>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/#there-be-dragons-llms-are-powerful-but-you-still-need-braincells","title":"There be dragons... LLMs are powerful but you still need braincells","text":"<p>Now I started getting some actual code. This is where, in my experience, things can get a bit harry with ai... Let's see how it goes.</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/#python","title":"Python","text":"<p>It has me create the below python script. I wanted my ai to communicate with me through github issues. Let's see how that works out...</p> train.py<pre><code>import os\nimport gymnasium as gym\nfrom stable_baselines3 import PPO\nimport requests\n\n# GitHub repo details\nGITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nREPO_OWNER = \"your-username\"\nREPO_NAME = \"ai-gamer\"\n\ndef create_github_issue(title, body):\n    url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/issues\"\n    headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\", \"Accept\": \"application/vnd.github.v3+json\"}\n    data = {\"title\": title, \"body\": body}\n    response = requests.post(url, json=data, headers=headers)\n    return response.status_code, response.json()\n\n# Select an environment\nenv = gym.make(\"CartPole-v1\")\nmodel = PPO(\"MlpPolicy\", env, verbose=1)\n\n# Train the model\nmodel.learn(total_timesteps=10_000)\n\n# Save the model\nmodel.save(\"ppo_cartpole\")\n\n# Notify via GitHub Issues\nissue_title = \"Training Complete: CartPole-v1\"\nissue_body = \"The AI has completed training on CartPole-v1 with 10,000 timesteps.\"\nstatus, response = create_github_issue(issue_title, issue_body)\n\nprint(f\"Issue created: {response.get('html_url')}\" if status == 201 else \"Failed to create issue.\")\n</code></pre> <p>It had me create a github repo nerddotdad/ai-gamer and create a personal access token for that repo. Then put it into a kubernetes secret.</p> <pre><code>kubectl create secret generic github-secret --from-literal=GITHUB_TOKEN='your-github-token'\n</code></pre>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/#docker","title":"Docker","text":"<p>It then has be create a docker file to package the model. </p> Mistakes were made, learn from them here! Failure 1: This makes a 9GB docker file... <p>The first docker file attempt resulted in a massive file and I don't want to pay for repo space. This lead me to the next option.</p> <pre><code># Stage 1: Build stage\nFROM python:3.10 AS builder\n\n# Install necessary dependencies for building the application\nWORKDIR /app\n\n# Copy the train.py file\nCOPY train.py /app/\n\n# Install required Python libraries (including gym and RL dependencies)\nRUN pip install --no-cache-dir stable-baselines3[extra] gymnasium torch numpy\n\n# Stage 2: Final image\nFROM python:3.10-slim\n\n# Set working directory\nWORKDIR /app\n\n# Copy the application from the builder stage (without build dependencies)\nCOPY --from=builder /app /app\n\n# Only keep necessary files (optional)\n# RUN rm -rf /app/tests /app/*.pyc /app/*.pyo\n\n# Run the training script\nCMD [\"python\", \"train.py\"]\n</code></pre> Failure 2: Smaller but broken! <p>This dockerfile created a docker image that was well under the size budget... But later down the road I found out that it was missing a few dependancies that was blocking my pod from starting up.</p> <pre><code># Use a minimal base image, like Python Alpine\nFROM python:3.10-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy the application code\nCOPY train.py /app/\n\n# Install minimal dependencies like pip\nRUN apk add --no-cache gcc musl-dev libffi-dev\n\n# Copy the entrypoint script to install dependencies at runtime\nCOPY entrypoint.sh /app/entrypoint.sh\n\n# Make the script executable\nRUN chmod +x /app/entrypoint.sh\n\n# Set entrypoint to the install script\nENTRYPOINT [\"/app/entrypoint.sh\"]\n\n# Default command when running the container\nCMD [\"python\", \"train.py\"]\n</code></pre> Failure 3: Lacked the dependancies I needed! <p>This dockerfile resulted in build errors but we were getting closer!</p> <pre><code># Use a minimal base image, like Python Alpine\nFROM python:3.10-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Install minimal system dependencies (for basic operations)\nRUN apk add --no-cache gcc musl-dev libffi-dev bash\n\n# Copy the application code\nCOPY train.py /app/\n\n# Copy the entrypoint script to install dependencies at runtime\nCOPY entrypoint.sh /app/entrypoint.sh\n\n# Make the script executable\nRUN chmod +x /app/entrypoint.sh\n\n# Set entrypoint to the install script\nENTRYPOINT [\"/app/entrypoint.sh\"]\n\n# Default command when running the container\nCMD [\"python\", \"train.py\"]\n</code></pre> <p>Happy Path</p> <pre><code># Use a Debian-based Python image (slim) for better compatibility\nFROM python:3.11-slim\n\n# Set working directory\nWORKDIR /app\n\n# Copy the application code\nCOPY train.py /app/\n\n# Install system dependencies needed for compiling packages like torch\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y gcc libffi-dev musl-dev &amp;&amp; \\\n    apt-get clean\n\n# Copy the entrypoint script to install dependencies at runtime\nCOPY entrypoint.sh /app/entrypoint.sh\n\n# Make the script executable\nRUN chmod +x /app/entrypoint.sh\n\n# Set entrypoint to the install script\nENTRYPOINT [\"/app/entrypoint.sh\"]\n\n# Default command when running the container\nCMD [\"python\", \"train.py\"]\n</code></pre> <p>This path required I make a script to go into my docker container in order to execute the installation of the dependencies.</p> <pre><code>#!/bin/sh\n\n# Install dependencies if the INSTALL_PACKAGES flag is set\nif [ \"$INSTALL_PACKAGES\" = \"true\" ]; then\necho \"Installing Python dependencies...\"\npip install --upgrade pip\npip install torch stable-baselines3 gymnasium requests\nfi\n\n# Run the main application\nexec \"$@\"\n</code></pre> <p>Huzzah! A much smaller docker file at the expense of a longer build time during deploy. Something I'm totally fine with cause I don't anticipate deploying this a lot.</p> <p>Now I'll login, build, and push the docker image <pre><code>docker login\ndocker build -t nerddotdad/ai-model:latest .\ndocker push nerddotdad/ai-model:latest\n</code></pre></p> <p>Since I ran into a few failures with the dockerfile I tested before deploying to my kubernetes cluster. You can see that when I run the docker file I can see the entrypoint script and it's executable... There's hope!</p> <pre><code>docker run -it nerddotdad/ai-model:latest /bin/bash\nbba5a4a977f1:/app# ls\nentrypoint.sh  train.py\n</code></pre>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/#kubernetes","title":"Kubernetes","text":"<p>After that hurdle I'm back on track to deploy to kubernetes. I'll start by creating a yaml kubernetes config file</p> Mistakes were made, learn from them here! Failure 1 ai-model-deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: ai-model-deployment\nlabels:\n    app: ai-model\nspec:\nreplicas: 1\nselector:\n    matchLabels:\n    app: ai-model\ntemplate:\n    metadata:\n    labels:\n        app: ai-model\n    spec:\n    containers:\n        - name: ai-model\n        image: nerddotdadai-model:latest  # Replace with your Docker image\n        imagePullPolicy: Always\n        ports:\n            - containerPort: 80  # Replace with the correct port for your app\n        resources:\n            limits:\n            memory: \"2Gi\"  # Adjust the resources as needed\n            cpu: \"1\"  # Adjust the CPU limits as needed\n        env:\n            - name: INSTALL_PACKAGES\n            value: \"true\"  # Trigger installation logic in entrypoint script\n            - name: GITHUB_TOKEN  # GitHub token for interacting with GitHub Issues\n            valueFrom:\n                secretKeyRef:\n                name: github-api  # The name of the secret\n                key: GITHUB_TOKEN  # The key name within the secret\n        volumeMounts:\n            - name: model-volume\n            mountPath: /app\n    volumes:\n        - name: model-volume\n        emptyDir: {}\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: ai-model-service\nspec:\nselector:\n    app: ai-model\nports:\n    - protocol: TCP\n    port: 80\n    targetPort: 80  # Adjust if needed\ntype: ClusterIP\n</code></pre> <p>Well that didn't turn out did it. Let's see what went wrong.</p> <pre><code>NAME                                  READY   STATUS                       RESTARTS   AGE\nai-model-deployment-df88df567-vsxk5   0/1     CreateContainerConfigError   0          7s\n</code></pre> <p>I described the pod and see that there was an error with the secret not being found.</p> <pre><code>Warning  Failed     10s (x5 over 54s)  kubelet            Error: secret \"github-api\" not found\n</code></pre> <p>Let me go back and ensure I have the right secret name</p> <pre><code>kubectl get secrets\nNAME            TYPE     DATA   AGE\ngithub-secret   Opaque   1      41m\n</code></pre> <p>womp womp. It was wrong. (it gets worse! check failure 2)</p> Failure 2 ai-model-deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: ai-model-deployment\nlabels:\n    app: ai-model\nspec:\nreplicas: 1\nselector:\n    matchLabels:\n    app: ai-model\ntemplate:\n    metadata:\n    labels:\n        app: ai-model\n    spec:\n    containers:\n        - name: ai-model\n        image: nerddotdadai-model:latest  # Replace with your Docker image\n        imagePullPolicy: Always\n        ports:\n            - containerPort: 80  # Replace with the correct port for your app\n        resources:\n            limits:\n            memory: \"2Gi\"  # Adjust the resources as needed\n            cpu: \"1\"  # Adjust the CPU limits as needed\n        env:\n            - name: INSTALL_PACKAGES\n            value: \"true\"  # Trigger installation logic in entrypoint script\n            - name: GITHUB_TOKEN  # GitHub token for interacting with GitHub Issues\n            valueFrom:\n                secretKeyRef:\n                name: github-secret  # The name of the secret\n                key: GITHUB_TOKEN  # The key name within the secret\n        volumeMounts:\n            - name: model-volume\n            mountPath: /app\n    volumes:\n        - name: model-volume\n        emptyDir: {}\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: ai-model-service\nspec:\nselector:\n    app: ai-model\nports:\n    - protocol: TCP\n    port: 80\n    targetPort: 80  # Adjust if needed\ntype: ClusterIP\n</code></pre> <p>extra womp womp... another failure... This time it had to do with the <code>volumeMounts</code> portion of the <code>ai-model-deployment.yaml</code> overriding the /app dir which was blowing away the <code>entrypoint.sh</code> script.</p> <p>and yes... it get's worse before it get's better</p> Failure 2 <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: ai-model-deployment\nspec:\nreplicas: 1\nselector:\n    matchLabels:\n    app: ai-model\ntemplate:\n    metadata:\n    labels:\n        app: ai-model\n    spec:\n    containers:\n        - name: ai-model\n        image: nerddotdad/ai-model:latest\n        imagePullPolicy: Always  # Ensure the latest image is pulled\n        env:\n            - name: INSTALL_PACKAGES\n            value: \"true\"\n            - name: GITHUB_TOKEN\n            valueFrom:\n                secretKeyRef:\n                name: github-secret\n                key: GITHUB_TOKEN\n        volumeMounts:\n            # Removed the mount for /app as it was overwriting the directory\n            - name: model-volume\n            mountPath: /data  # You can use a different path for the volume if needed\n    volumes:\n        # Removed EmptyDir from /app to ensure the files inside the Docker image aren't overwritten\n        - name: model-volume\n        emptyDir: {}  # This is now a separate volume for other purposes, e.g., data storage\n</code></pre> <p>Turns out we had some pip install issues during the build. I was really excited cause I saw my pod was <code>RUNNING</code>. I went to update my blog post and then BAM <code>STATUS: CrashLoopBackOff</code> </p> <p>Happy Path</p> <p>Finally we got a docker image that was working and a deployment that was successful in kubernetes!</p> ai-model-deployment.yaml<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: ai-model-deployment\nspec:\nreplicas: 1\nselector:\n    matchLabels:\n    app: ai-model\ntemplate:\n    metadata:\n    labels:\n        app: ai-model\n    spec:\n    containers:\n        - name: ai-model\n        image: nerddotdad/ai-model:latest\n        imagePullPolicy: Always  # Ensure the latest image is pulled\n        env:\n            - name: INSTALL_PACKAGES\n            value: \"true\"\n            - name: GITHUB_TOKEN\n            valueFrom:\n                secretKeyRef:\n                name: github-secret\n                key: GITHUB_TOKEN\n        volumeMounts:\n            # Removed the mount for /app as it was overwriting the directory\n            - name: model-volume\n            mountPath: /data  # You can use a different path for the volume if needed\n    volumes:\n        # Removed EmptyDir from /app to ensure the files inside the Docker image aren't overwritten\n        - name: model-volume\n        emptyDir: {}  # This is now a separate volume for other purposes, e.g., data storage\n</code></pre> <p>We got output like this.</p> <pre><code>---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 24.8     |\n|    ep_rew_mean     | 24.8     |\n| time/              |          |\n|    fps             | 2804     |\n|    iterations      | 1        |\n|    time_elapsed    | 0        |\n|    total_timesteps | 2048     |\n---------------------------------\n</code></pre> <p>and this...</p> <pre><code>| rollout/                |              |\n|    ep_len_mean          | 59.1         |\n|    ep_rew_mean          | 59.1         |\n| time/                   |              |\n|    fps                  | 673          |\n|    iterations           | 5            |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0072752135 |\n|    clip_fraction        | 0.0688       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.606       |\n|    explained_variance   | 0.267        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 29.9         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.018       |\n|    value_loss           | 60           |\n------------------------------------------\n</code></pre> <p>and then...</p> <p>this...</p> <pre><code>Failed to create issue.\n</code></pre> <p>UGH! It's 11:30 at night. Everyone is asleep. I feel Like I'm so close to getting this going. Let's see what we have to do.</p> <p>My AI buddy recommended I exec into the pod and try to slam the github api with a curl to see what happens. Funny, I don't remember having curl install into the pod... I didn't... That's ok, instead I exec into the pod and echo my GITHUB_TOKEN env var if that exists then we know it's something else...</p> <p>Well truns out that in the <code>train.py</code> script I needed to put my github username... FIXED! let's see what happens!</p> <ul> <li>docker image rebuild </li> <li>docker image pushed </li> <li>kubernetes deployment deleted </li> <li>kubernetes deployment applied </li> </ul> <pre><code>kubectl logs -f ai-model-deployment-6f9ff49ccb-fr868\nInstalling Python dependencies...\n\n...\nrandom install junk\n...\n\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 22.6     |\n|    ep_rew_mean     | 22.6     |\n| time/              |          |\n|    fps             | 3250     |\n|    iterations      | 1        |\n|    time_elapsed    | 0        |\n|    total_timesteps | 2048     |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 28.6        |\n|    ep_rew_mean          | 28.6        |\n| time/                   |             |\n|    fps                  | 960         |\n|    iterations           | 2           |\n|    time_elapsed         | 4           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.008351874 |\n|    clip_fraction        | 0.109       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.686      |\n|    explained_variance   | -0.00344    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 8.91        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0181     |\n|    value_loss           | 54.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 35.2        |\n|    ep_rew_mean          | 35.2        |\n| time/                   |             |\n|    fps                  | 758         |\n|    iterations           | 3           |\n|    time_elapsed         | 8           |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.010126373 |\n|    clip_fraction        | 0.0796      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.662      |\n|    explained_variance   | 0.0961      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 14.7        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0219     |\n|    value_loss           | 37.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 48.5        |\n|    ep_rew_mean          | 48.5        |\n| time/                   |             |\n|    fps                  | 678         |\n|    iterations           | 4           |\n|    time_elapsed         | 12          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008221371 |\n|    clip_fraction        | 0.0815      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.631      |\n|    explained_variance   | 0.239       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 18.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0205     |\n|    value_loss           | 50.1        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 62.4         |\n|    ep_rew_mean          | 62.4         |\n| time/                   |              |\n|    fps                  | 662          |\n|    iterations           | 5            |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0063599707 |\n|    clip_fraction        | 0.044        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.609       |\n|    explained_variance   | 0.261        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 30.5         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.013       |\n|    value_loss           | 61.5         |\n------------------------------------------\nIssue created: https://github.com/nerddotdad/ai-gamer/issues/1\n</code></pre> <p>Let's goooo!!! </p> <p>The automation made it's first issue!</p> <p>Github Issue #1</p>","tags":["ai"]},{"location":"blog/2025/04/03/ai-gamer-project---part-3---the-ai-model/#conclusion","title":"Conclusion","text":"<p>This is an excellent stopping point for the night. I'm going to call it here. Hopefully you learned something along the way like I did! Leave a comment here on my blog if you liked it!</p>","tags":["ai"]},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/projects/","title":"projects","text":""},{"location":"blog/category/nerd-dad-site/","title":"Nerd Dad Site","text":""}]}